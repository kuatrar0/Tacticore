# ðŸŽ¯ GuÃ­a de Entrenamiento Manual - Tacticore ML

## ðŸ“‹ Flujo de Entrenamiento Manual

Esta guÃ­a te ayudarÃ¡ a continuar entrenando tu modelo de Machine Learning de manera manual y controlada.

## ðŸš€ **Flujo Recomendado**

### **OpciÃ³n 1: Streamlit App (Recomendado)**
```bash
# 1. Ejecutar la aplicaciÃ³n
streamlit run src/streamlit_app/app.py

# 2. En la app:
#    - Seleccionar "ML Training Mode"
#    - Subir tu archivo de labels existente
#    - Usar "Active Learning" para ver los kills mÃ¡s importantes
#    - Etiquetar manualmente uno por uno o en modo "Batch"
```

### **OpciÃ³n 2: Docker (Si prefieres contenedores)**
```bash
# 1. Iniciar la aplicaciÃ³n
docker-compose up --build

# 2. Abrir en el navegador
# http://localhost:8501

# 3. Usar la interfaz web para etiquetar manualmente
```

## ðŸ“ **Estructura de Archivos Recomendada**

```
Tacticore/
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ imperial-vs-shinden-m1-mirage/
â”‚       â”œâ”€â”€ kills.parquet
â”‚       â”œâ”€â”€ ticks.parquet
â”‚       â”œâ”€â”€ grenades.parquet
â”‚       â””â”€â”€ ...
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ labeled_data.csv              # Tus labels existentes
â”‚   â”œâ”€â”€ features_labeled_context.csv # Features generadas
â”‚   â”œâ”€â”€ active_learning_samples.csv  # Muestras para etiquetar
â”‚   â””â”€â”€ models/                       # Modelos entrenados
â”‚       â”œâ”€â”€ tacticore_model_attackerlabel.pkl
â”‚       â””â”€â”€ tacticore_model_victimlabel.pkl
â””â”€â”€ scripts/
    â””â”€â”€ training_workflow.md
```

## ðŸ”„ **Proceso de Entrenamiento Manual**

### **Paso 1: Preparar Datos**
1. **AsegÃºrate de tener tus archivos de datos**:
   - `dataset/imperial-vs-shinden-m1-mirage/kills.parquet`
   - `dataset/imperial-vs-shinden-m1-mirage/ticks.parquet`
   - `dataset/imperial-vs-shinden-m1-mirage/grenades.parquet` (opcional)

2. **Si tienes labels existentes**:
   - GuÃ¡rdalos en `results/labeled_data.csv`

### **Paso 2: Iniciar la AplicaciÃ³n**

**OpciÃ³n A: Streamlit Directo**
```bash
streamlit run src/streamlit_app/app.py
```

**OpciÃ³n B: Docker**
```bash
docker-compose up --build
# Luego ir a http://localhost:8501
```

### **Paso 3: Configurar en la App**
1. **Seleccionar modo**: "ML Training Mode"
2. **Subir archivos**:
   - `kills.parquet`
   - `ticks.parquet`
   - `grenades.parquet` (opcional)
3. **Subir labels existentes**: Si tienes un archivo CSV con labels
4. **Configurar mapa**: Las rutas ya estÃ¡n corregidas

### **Paso 4: Etiquetar Manualmente**
1. **Usar Active Learning**: La app te mostrarÃ¡ los kills mÃ¡s importantes
2. **Etiquetar uno por uno**: Revisar cada kill y aplicar labels manualmente
3. **Modo Batch**: Etiquetar mÃºltiples kills de una vez (pero manualmente)
4. **Auto-retraining**: El modelo se reentrena automÃ¡ticamente cuando agregas labels

## ðŸŽ¯ **Mejores PrÃ¡cticas**

### **1. Frecuencia de Entrenamiento**
- **Reentrenar cada 10-20 nuevos labels**
- **Usar Active Learning para priorizar kills importantes**
- **Revisar mÃ©tricas del modelo regularmente**

### **2. Calidad de Labels**
- **Ser consistente con los criterios de etiquetado**
- **Etiquetar mÃºltiples aspectos cuando sea relevante**
- **Revisar labels anteriores ocasionalmente**

### **3. OrganizaciÃ³n de Datos**
- **Mantener backup de labels importantes**
- **Versionar modelos entrenados**
- **Documentar cambios en criterios de etiquetado**

## ðŸ“Š **Monitoreo del Progreso**

### **MÃ©tricas a Revisar en la App**
1. **Accuracy del modelo** (objetivo: >80%)
2. **NÃºmero de labels por clase** (balancear clases)
3. **Uncertainty scores** (priorizar kills inciertos)

### **Verificar Progreso**
- **En la app**: Ver las mÃ©tricas en tiempo real
- **Exportar datos**: Descargar tu dataset etiquetado
- **Revisar modelos**: Los modelos se guardan automÃ¡ticamente

## ðŸš¨ **SoluciÃ³n de Problemas Comunes**

### **Error: "Map data file not found"**
âœ… **SOLUCIONADO** - Las rutas han sido corregidas

### **Error: "No labeled samples found"**
- Verificar que tienes labels en la app
- Usar "Import Labeled Data" para cargar labels existentes

### **Modelo con baja accuracy**
1. **Revisar balance de clases** en la app
2. **Aumentar nÃºmero de labels**
3. **Verificar calidad de etiquetado**

## ðŸŽ¯ **Workflow Diario Recomendado**

### **SesiÃ³n de 30 minutos:**
1. **5 min**: Iniciar app y cargar datos
2. **20 min**: Etiquetar usando Active Learning
3. **5 min**: Revisar mÃ©tricas en la app

### **SesiÃ³n de 1 hora:**
1. **10 min**: Revisar mÃ©tricas y ajustar filtros
2. **40 min**: Etiquetar en modo intensivo
3. **10 min**: Exportar datos y revisar resultados

## ðŸ“ˆ **Objetivos de Entrenamiento**

### **Fase 1: Base (0-100 labels)**
- **Objetivo**: 60% accuracy
- **Enfoque**: Etiquetar casos obvios y diversos
- **Frecuencia**: Reentrenar cada 20 labels

### **Fase 2: Mejora (100-500 labels)**
- **Objetivo**: 75% accuracy
- **Enfoque**: Usar Active Learning intensivamente
- **Frecuencia**: Reentrenar cada 50 labels

### **Fase 3: Refinamiento (500+ labels)**
- **Objetivo**: 85%+ accuracy
- **Enfoque**: Casos edge y correcciÃ³n de errores
- **Frecuencia**: Reentrenar cada 100 labels

## ðŸŽ¯ **ConclusiÃ³n**

Este flujo te permitirÃ¡:
- âœ… **Etiquetar manualmente con control total**
- âœ… **Priorizar los kills mÃ¡s importantes para el modelo**
- âœ… **Mantener un proceso organizado y escalable**
- âœ… **Monitorear el progreso del modelo en tiempo real**

**RecomendaciÃ³n**: Usa la **aplicaciÃ³n Streamlit** para un control completo y manual del proceso de etiquetado.

